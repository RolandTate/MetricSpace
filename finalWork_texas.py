#!/usr/bin/env python3
"""
MetricSpace æ‰¹å¤„ç†è¿è¡Œè„šæœ¬
è‡ªåŠ¨åˆ›å»ºé…ç½®å¹¶è¿è¡Œæµ‹è¯•ï¼Œæ— éœ€æ‰‹åŠ¨è¾“å…¥
"""

import csv
import os
import re
import subprocess
import sys
from typing import Dict, Optional, Tuple

from Utils.config import save_config, DEFAULT_CONFIG

# æ¯ä¸ªå®éªŒé‡å¤æ¬¡æ•°
NUM_REPEATS = 5


def _parse_batch_stats_from_stdout(stdout: str) -> Optional[Tuple[float, float, float, float, float]]:
    """
    ä» config_main.py çš„è¾“å‡ºä¸­è§£ææ‰¹é‡æŸ¥è¯¢ç»Ÿè®¡ç»“æœï¼š
    å¹³å‡ç»“æœä¸ªæ•°ã€ç»“æœä¸ªæ•°æ ‡å‡†å·®ã€å¹³å‡è·ç¦»è®¡ç®—æ¬¡æ•°ã€æ ‡å‡†å·®ã€æ–¹å·®
    """
    # ç›®æ ‡è¡Œç¤ºä¾‹ï¼š
    # æ‰¹é‡æŸ¥è¯¢å®Œæˆï¼Œæ€»æŸ¥è¯¢æ•°: 1000ï¼Œå¹³å‡ç»“æœä¸ªæ•°: 5.23ï¼Œç»“æœä¸ªæ•°æ ‡å‡†å·®: 2.34ï¼Œå¹³å‡è·ç¦»è®¡ç®—æ¬¡æ•°: 123.45ï¼Œæ ‡å‡†å·®: 12.34ï¼Œæ–¹å·®: 152.34
    for line in stdout.splitlines():
        if "å¹³å‡ç»“æœä¸ªæ•°" in line and "ç»“æœä¸ªæ•°æ ‡å‡†å·®" in line and "å¹³å‡è·ç¦»è®¡ç®—æ¬¡æ•°" in line and "æ ‡å‡†å·®" in line and "æ–¹å·®" in line:
            # æå–è¯¥è¡Œä¸­çš„æ‰€æœ‰æ•°å­—
            # é¡ºåºï¼šæ€»æŸ¥è¯¢æ•°, å¹³å‡ç»“æœä¸ªæ•°, ç»“æœä¸ªæ•°æ ‡å‡†å·®, å¹³å‡è·ç¦»è®¡ç®—æ¬¡æ•°, æ ‡å‡†å·®, æ–¹å·®
            nums = re.findall(r"[-+]?\d*\.?\d+(?:[eE][-+]?\d+)?", line)
            if len(nums) >= 6:
                try:
                    avg_result = float(nums[1])  # å¹³å‡ç»“æœä¸ªæ•°
                    std_result = float(nums[2])  # ç»“æœä¸ªæ•°æ ‡å‡†å·®
                    avg_calc = float(nums[3])  # å¹³å‡è·ç¦»è®¡ç®—æ¬¡æ•°
                    std_calc = float(nums[4])  # æ ‡å‡†å·®
                    var_calc = float(nums[5])  # æ–¹å·®
                    return avg_result, std_result, avg_calc, std_calc, var_calc
                except ValueError:
                    return None
    return None


def create_and_run_test(test_name: str, config: Dict) -> Optional[Dict]:
    """
    åˆ›å»ºé…ç½®å¹¶è¿è¡Œæµ‹è¯•ã€‚
    æ¯ä¸ªå®éªŒé‡å¤ NUM_REPEATS æ¬¡ï¼Œå–ç»Ÿè®¡é‡çš„å¹³å‡å€¼ï¼Œå¹¶è¿”å›æ±‡æ€»ç»“æœå­—å…¸ã€‚
    """
    config_file = f"./config/{test_name}.json"
    save_config(config, config_file)

    print(f"\n=== è¿è¡Œ {test_name} æµ‹è¯•ï¼ˆé‡å¤ {NUM_REPEATS} æ¬¡ï¼‰ ===")
    print(f"é…ç½®æ–‡ä»¶: {config_file}")

    stats_list = []  # æ¯æ¬¡è¿è¡Œè§£æåˆ°çš„ (avg_result, std_result, avg_calc, std_calc, var_calc)

    try:
        for run_idx in range(1, NUM_REPEATS + 1):
            print(f"\n--- ç¬¬ {run_idx}/{NUM_REPEATS} æ¬¡è¿è¡Œ ---")
            # è¿è¡Œæµ‹è¯•
            result = subprocess.run(
                [sys.executable, "config_main.py", config_file],
                capture_output=True,
                text=True,
                encoding="utf-8",
            )

            if result.returncode == 0:
                print(f"âœ… {test_name} ç¬¬ {run_idx} æ¬¡æµ‹è¯•æˆåŠŸå®Œæˆ")
                # åªæ‰“å°å…³é”®ä¿¡æ¯ï¼Œå®Œæ•´ stdout å¦‚æœ‰éœ€è¦å¯å•ç‹¬æŸ¥çœ‹
                parsed = _parse_batch_stats_from_stdout(result.stdout)
                if parsed is not None:
                    avg_result, std_result, avg_calc, std_calc, var_calc = parsed
                    stats_list.append(parsed)
                    print(
                        f"æœ¬æ¬¡ç»Ÿè®¡: å¹³å‡ç»“æœä¸ªæ•°={avg_result:.2f}, ç»“æœä¸ªæ•°æ ‡å‡†å·®={std_result:.2f}, "
                        f"å¹³å‡è·ç¦»è®¡ç®—æ¬¡æ•°={avg_calc:.2f}, æ ‡å‡†å·®={std_calc:.2f}, æ–¹å·®={var_calc:.2f}"
                    )
                else:
                    print("âš  æœªèƒ½ä»è¾“å‡ºä¸­è§£æç»Ÿè®¡ç»“æœï¼ŒåŸå§‹è¾“å‡ºå¦‚ä¸‹ï¼š")
                    print(result.stdout)
            else:
                print(f"âŒ {test_name} ç¬¬ {run_idx} æ¬¡æµ‹è¯•å¤±è´¥")
                print("é”™è¯¯è¾“å‡º:")
                print(result.stderr)

    except subprocess.TimeoutExpired:
        print(f"â° {test_name} æµ‹è¯•è¶…æ—¶")
    except Exception as e:
        print(f"âŒ {test_name} æµ‹è¯•å¼‚å¸¸: {e}")
    finally:
        # æ¸…ç†é…ç½®æ–‡ä»¶
        try:
            os.remove(config_file)
        except OSError:
            pass

    if not stats_list:
        print(f"âš  {test_name} æœªè·å¾—æœ‰æ•ˆçš„ç»Ÿè®¡ç»“æœ")
        return None

    # å¯¹ NUM_REPEATS æ¬¡è¿è¡Œå¾—åˆ°çš„ç»Ÿè®¡é‡å†å–å¹³å‡ï¼Œä½œä¸ºè¯¥å®éªŒçš„æœ€ç»ˆç»“æœ
    avg_result_mean = sum(s[0] for s in stats_list) / len(stats_list)
    std_result_mean = sum(s[1] for s in stats_list) / len(stats_list)
    avg_calc_mean = sum(s[2] for s in stats_list) / len(stats_list)
    std_calc_mean = sum(s[3] for s in stats_list) / len(stats_list)
    var_calc_mean = sum(s[4] for s in stats_list) / len(stats_list)

    print(
        f"\n=== {test_name} å®éªŒæœ€ç»ˆç»“æœï¼ˆ{len(stats_list)} æ¬¡æœ‰æ•ˆè¿è¡Œçš„å¹³å‡ï¼‰===\n"
        f"å¹³å‡ç»“æœä¸ªæ•°(å¹³å‡å): {avg_result_mean:.2f}\n"
        f"ç»“æœä¸ªæ•°æ ‡å‡†å·®(å¹³å‡å): {std_result_mean:.2f}\n"
        f"å¹³å‡è·ç¦»è®¡ç®—æ¬¡æ•°(å¹³å‡å): {avg_calc_mean:.2f}\n"
        f"æ ‡å‡†å·®(å¹³å‡å): {std_calc_mean:.2f}\n"
        f"æ–¹å·®(å¹³å‡å): {var_calc_mean:.2f}"
    )

    # æ–¹ä¾¿åç»­ç”»å›¾çš„ç»“æ„åŒ–ç»“æœ
    summary = {
        "test_name": test_name,
        "dataset": config.get("dataset", {}).get("name", ""),
        "load_count": config.get("dataset", {}).get("load_count", ""),
        "distance_vector": config.get("distance_function", {}).get("vector", ""),
        "distance_string": config.get("distance_function", {}).get("string", ""),
        "pivot_selector": config.get("pivot_selector", {}).get("name", ""),
        "index_structure": config.get("index_structure", {}).get("name", ""),
        "batch_radius": config.get("batch_radius", ""),
        "batch_query_num": config.get("batch_query_num", ""),
        "num_repeats": len(stats_list),
        "avg_result_mean": avg_result_mean,
        "std_result_mean": std_result_mean,
        "avg_calc_mean": avg_calc_mean,
        "std_calc_mean": std_calc_mean,
        "var_calc_mean": var_calc_mean,
    }
    return summary


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰é¢„è®¾æµ‹è¯•"""

    pivot_selection_comparison_tests = []

    texas_002_LPT_eu_FFT = DEFAULT_CONFIG.copy()
    texas_002_LPT_eu_FFT.update({
        "dataset": {"name": "texas", "load_count": 10000},
        "distance_function": {"vector": "Euclidean Distance", "string": "Weighted Edit Distance"},
        "pivot_selector": {
            "name": "Farthest First Traversal",
            # å¯é€‰: "Manual", "Random", "Max Variance", "Farthest First Traversal", "Incremental Sampling"
            "params": {
                # éšæœºé€‰æ‹©æ”¯æ’‘ç‚¹å‚æ•°
                "seed": 0,
            }
        },
        "index_structure": {
            "name": "Linear Partition Tree",
            "max_leaf_size": 30,
            "pivot_k": 1,
            "lpt_matrix_A": [[1, -1, 0], [1, 1, 0], [0, 0, 1]],  # LPTç‰¹æœ‰å‚æ•°
            "lpt_num_regions": 2  # LPTç‰¹æœ‰å‚æ•°
        },
        "queries": [
            # {"radius": 0.02, "query_point": "auto", "description": "å°åŠå¾„æŸ¥è¯¢"}
        ],
        # è¿è¡Œæ¨¡å¼
        "run_mode": "batch_query_statistics",  # "interactive" æˆ– "batch"
        "batch_radius": 0.0410,
        "batch_query_num": 1000,
        "auto_generate_queries": True,  # æ˜¯å¦è‡ªåŠ¨ç”ŸæˆæŸ¥è¯¢ç‚¹
        "show_results": False,  # æ˜¯å¦æ˜¾ç¤ºæŸ¥è¯¢ç»“æœ
        "exit_after_queries": False  # æ˜¯å¦åœ¨å®Œæˆé¢„è®¾æŸ¥è¯¢åé€€å‡º
    })
    pivot_selection_comparison_tests.append(("texas_002_LPT_eu_FFT", texas_002_LPT_eu_FFT))

    texas_004_LPT_eu_FFT = texas_002_LPT_eu_FFT.copy()
    texas_004_LPT_eu_FFT.update({
        "batch_radius": 0.0804,
    })
    pivot_selection_comparison_tests.append(("texas_004_LPT_eu_FFT", texas_004_LPT_eu_FFT))

    texas_006_LPT_eu_FFT = texas_002_LPT_eu_FFT.copy()
    texas_006_LPT_eu_FFT.update({
        "batch_radius": 0.1236,
    })
    pivot_selection_comparison_tests.append(("texas_006_LPT_eu_FFT", texas_006_LPT_eu_FFT))

    texas_008_LPT_eu_FFT =texas_002_LPT_eu_FFT.copy()
    texas_008_LPT_eu_FFT.update({
        "batch_radius": 0.1728,
    })
    pivot_selection_comparison_tests.append(("texas_008_LPT_eu_FFT", texas_008_LPT_eu_FFT))

    texas_010_LPT_eu_FFT = texas_002_LPT_eu_FFT.copy()
    texas_010_LPT_eu_FFT.update({
        "batch_radius": 0.2157,
    })
    pivot_selection_comparison_tests.append(("texas_010_LPT_eu_FFT", texas_010_LPT_eu_FFT))

    texas_002_MVPT_eu_FFT = texas_002_LPT_eu_FFT.copy()
    texas_002_MVPT_eu_FFT.update({
        "index_structure": {
            "name": "Multiple Vantage Point Tree",
            "max_leaf_size": 30,
            "pivot_k": 1,
            "mvpt_regions": 2,  # MVPTç‰¹æœ‰å‚æ•°
            "mvpt_internal_pivots": 3  # MVPTç‰¹æœ‰å‚æ•°
        }
    })
    pivot_selection_comparison_tests.append(
        ("texas_002_MVPT_eu_FFT", texas_002_MVPT_eu_FFT))

    texas_004_MVPT_eu_FFT = texas_002_MVPT_eu_FFT.copy()
    texas_004_MVPT_eu_FFT.update({
        "batch_radius": 0.0804,
    })
    pivot_selection_comparison_tests.append(
        ("texas_004_MVPT_eu_FFT", texas_004_MVPT_eu_FFT))

    texas_006_MVPT_eu_FFT = texas_002_MVPT_eu_FFT.copy()
    texas_006_MVPT_eu_FFT.update({
        "batch_radius": 0.1236,
    })
    pivot_selection_comparison_tests.append(
        ("texas_006_MVPT_eu_FFT", texas_006_MVPT_eu_FFT))

    texas_008_MVPT_eu_FFT = texas_002_MVPT_eu_FFT.copy()
    texas_008_MVPT_eu_FFT.update({
        "batch_radius": 0.1728,
    })
    pivot_selection_comparison_tests.append(
        ("texas_008_MVPT_eu_FFT", texas_008_MVPT_eu_FFT))

    texas_010_MVPT_eu_FFT = texas_002_MVPT_eu_FFT.copy()
    texas_010_MVPT_eu_FFT.update({
        "batch_radius": 0.2157,
    })
    pivot_selection_comparison_tests.append(
        ("texas_010_MVPT_eu_FFT", texas_010_MVPT_eu_FFT))

    # è¿è¡Œæµ‹è¯•
    print("ğŸš€ å¼€å§‹è¿è¡Œ MetricSpace æ‰¹å¤„ç†æµ‹è¯•")
    print("=" * 50)

    # ç»“æœä¿å­˜ç›¸å…³è®¾ç½®
    os.makedirs("./results", exist_ok=True)
    results_file = "results/LPT(orthogonal)_MVPT(no_inclusive)_texas_comparison_batch_stats.csv"
    summaries = []

    # æ”¯æ’‘ç‚¹é€‰æ‹©ç®—æ³•å¯¹æ¯”æµ‹è¯•
    print("\nğŸ“Š æ”¯æ’‘ç‚¹é€‰æ‹©ç®—æ³•å¯¹æ¯”æµ‹è¯•")
    print("-" * 30)
    for test_name, test_config in pivot_selection_comparison_tests:
        summary = create_and_run_test(f"objective function {test_name}", test_config)
        if summary is not None:
            summaries.append(summary)

    # å°†æ‰€æœ‰å®éªŒçš„æœ€ç»ˆç»“æœå†™å…¥ CSVï¼Œæ–¹ä¾¿åç»­ç”»å›¾
    if summaries:
        fieldnames = [
            "test_name",
            "dataset",
            "load_count",
            "distance_vector",
            "distance_string",
            "pivot_selector",
            "index_structure",
            "batch_radius",
            "batch_query_num",
            "num_repeats",
            "avg_result_mean",
            "std_result_mean",
            "avg_calc_mean",
            "std_calc_mean",
            "var_calc_mean",
        ]
        with open(results_file, "w", newline="", encoding="utf-8") as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            for s in summaries:
                writer.writerow(s)
        print(f"\nğŸ“ æ‰€æœ‰å®éªŒçš„æœ€ç»ˆç»“æœå·²ä¿å­˜åˆ°: {results_file}")
    else:
        print("\nâš  æ²¡æœ‰å¯ä¿å­˜çš„å®éªŒç»“æœ")

    print("\nâœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")


if __name__ == "__main__":
    run_all_tests()
